# AI

Basics of Deep Learning
- [RNN](#rnn)
- [CNNs](#cnn)
- [LSTMs](#lstm)
- Some [Architecture](#architecture) 
- [Transformers](#transformers)
- [Vision Transformers](#vision-transformers)

## RNN
Simple RNN: Create a basic RNN model for Shakespear text
- Implement a training loop 
- Train on small [dataset](https://huggingface.co/datasets/karpathy/tiny_shakespeare)
- Evaluate the results

## CNN
Image classification on MNIST
- Train the CNN on [MNIST](https://huggingface.co/datasets/ylecun/mnist)

## LSTM
LSTM model for Shakespear text
- Same as RNN, train on [dataset](https://huggingface.co/datasets/karpathy/tiny_shakespeare)
- Find differnces in RNN and Lstm results 

## Architecture
- [ResNets](https://en.wikipedia.org/wiki/Residual_neural_network)
- [AlexNet](https://en.wikipedia.org/wiki/AlexNet)
- [YOLO](https://docs.ultralytics.com/)

## Transformers
- Create a translation model from English to any language of your choice
- datasets required can be found on huggingface datasets

## Vision Transformers
- Read about Vision Transformers
- Try to implement [CLIP](https://openai.com/index/clip/) for image captioning